<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on Davide</title>
    <link>/tags/data-science/</link>
    <description>Recent content in Data Science on Davide</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zn-Hans</language>
    <lastBuildDate>Tue, 23 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ARIMA Timeseries Forecasting in R </title>
      <link>/blog/2018-10/arima-timeseries-forecasting-in-r/</link>
      <pubDate>Tue, 23 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-10/arima-timeseries-forecasting-in-r/</guid>
      <description>Auto Regressive Integration of Moving Averages This report aims to explain the desired outcome of the ‘Auto Regressive Integration of Moving Averages’ (ARIMA) model in it’s application towards forecasting energy demand in Australia, as well as the assumptions and limitations that are present through the use of an ARIMA model. ARIMA models are a widely used industry standard for timeseries forecasting.
Definition  A timeseries which needs to be differenced to be made stationary is an “integrated” (I) series. Lags of the stationarized series are called “auto-regressive” (AR) terms. Lags of the forecast errors are called “moving average” (MA) terms.   A Very Short History ARIMA models have risen to prominence in recent times though they are an adaptation of a discrete-time filtering method developed in the 1930s by electrical engineers (Norbert Weiner et al). Since then, statisticians George Box and Gwilym Jenkins developed systematic methods for applying them to business and economic data in the 1970s (ARIMA models are also sometimes referred to as “Box-Jenkins” models).
 ARIMA Terminology A non-seasonal ARIMA model is summarized by three key terms:
 p = the number of autoregressive terms d = the number of nonseasonal differences q = the number of moving-average terms  This is called an “ARIMA(p,d,q)” model</description>
    </item>
    
    <item>
      <title>STDS Assessment 2C</title>
      <link>/blog/2018-10/stds-assessment-2c/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-10/stds-assessment-2c/</guid>
      <description>Project Review and Contribution to Community   ‘High Voltage’ Group Dynamics   Paul Robertson Edward Truong Mutaz Abu Ghazzaleh Justin White Davide Lorino (myself)  Working with these four individuals in the process of delivering Assessment 2 (and a variety of side projects - see the ‘Apps’ subheading of ‘Contribution to Statistical Thinking Community’ below) was an immense pleasure. Having previously worked with Edward and Paul in Data Science for Innovation and taken Data Algorithms and Meaning with Mutaz (having had many conversations about statistical concepts together) and also working with somebody I hadn’t met yet - Justin White - I was really excited to take on this project together.
  Group Highlights Working with this group was great because everybody had lots to contribute to the group discussions. Edward was an excellent custodian of our master document and would always keep us on-task with our specific component of the project. Paul had fantastic contributions with his modelling of the data as a timeseries. Mutaz made huge breakthroughs with our analysis when he discovered that our data more closely resembled a polynomial distributions, and Justin acquired the temperature data that would ultimately play a significant role in explaining the variance in energy demand.</description>
    </item>
    
    <item>
      <title>Text Analysis with visNetwork</title>
      <link>/blog/2018-07/text-analysis-with-visnetwork/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-07/text-analysis-with-visnetwork/</guid>
      <description>Text Analysis is growing in popularity just about everywhere - it’s an abundant source of data that until recently most analysts have ignored because of it’s unwieldy structure. Recent developments and packages in the R programming language have made it easy to derive significant meaning from a text corpus.
Practical Applications of Text Analysis  Analysing email data (e.g. from a customer service inbox to analyze queries and feedback), Web scraping (e.g. Cambridge Analytica, though always consider the ethical implications of such methods even if the data is publicly available or rightfully yours to share), Literary analysis (e.g. poems (Shelley vs Byron) and speeches (Obama vs Trump))  In this post we’ll look at the Australian Election Speeches 1901 - 2016 dataset provided by https://electionspeeches.moadoph.gov.au/speeches - we’ll connect R to their API to read the data, then we’ll clean, analyze and visualize the data with some helpful R packages.
library(jsonlite) library(readr) library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union  Connecting to the API Running the line below will pull the speeches data directly from the API of the Museum of Australian Democracy</description>
    </item>
    
  </channel>
</rss>